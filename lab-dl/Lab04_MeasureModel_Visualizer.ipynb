{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H15JTA46716v"
      },
      "source": [
        "# Measuring FLOPs\n",
        "MACs (Multiply-Accumulate Operations) and FLOPs (Floating Point Operations) are two metrics used to measure inference speed of models\n",
        "\n",
        "\n",
        "Minimizing MACs/FLOPs helps in building faster to real-time models.\n",
        "\n",
        "\n",
        "\n",
        "Check out [ref] for more.\n",
        "\n",
        "[ref]: https://medium.com/@pashashaik/a-guide-to-hand-calculating-flops-and-macs-fa5221ce5ccc\n",
        "\n",
        "Library used: [thop]\n",
        "\n",
        "[thop]: https://github.com/Lyken17/pytorch-OpCounter\n",
        "\n",
        "Other tool(s): [fvcore]\n",
        "\n",
        "[fvcore]: https://github.com/facebookresearch/fvcore/blob/main/docs/flop_count.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYPzeWkq6063",
        "outputId": "1c40edc7-0ede-4118-d3f7-54e98000e858"
      },
      "outputs": [],
      "source": [
        "!pip install thop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9W4U90l708H",
        "outputId": "13599f1a-bdf9-47dd-84b6-d1f5e83a118c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision.models import resnet34, resnet18\n",
        "from thop import profile\n",
        "from thop import clever_format\n",
        "\n",
        "model = resnet34()\n",
        "input = torch.randn(1, 3, 224, 224)\n",
        "flops, params = profile(model, inputs=(input, ))\n",
        "flops, params = clever_format([flops, params], \"%.3f\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RgTOvdS4-Co",
        "outputId": "94b09101-6ba0-4582-b9c1-94d3c632f0ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('3.679G', '21.798M')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flops, params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBTObhek_Yiz",
        "outputId": "75211b88-9715-4d04-a5c4-ddd3c3bb723c"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Collecting torchsummary\n",
            "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
            "Installing collected packages: torchsummary\n",
            "Successfully installed torchsummary-1.5.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k43TXbKx5H_s",
        "outputId": "0370f641-6af2-45fc-e2de-5de79a4f5800"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3,224,224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-z3S4mE6Grh"
      },
      "source": [
        "# Converting models to ONNX and visualize\n",
        "\n",
        "ONNX, or Open Neural Network Exchange, is an open format for representing machine learning (ML) models. It defines a computation graph model, as well as definitions of built-in operators and standard data types. ONNX is widely supported by many ML frameworks, tools, and hardware platforms.\n",
        "\n",
        "One of the main benefits of ONNX is that it enables interoperability between different ML frameworks. This means that you can train a model in one framework, such as TensorFlow or PyTorch, and then export it to ONNX. You can then use the ONNX model in another framework, or on a different hardware platform, without having to retrain the model.\n",
        "\n",
        "Another benefit of ONNX is that it makes it easier to deploy ML models in production. There are many ONNX-compatible runtimes and libraries that can be used to accelerate inference on a variety of hardware platforms, including CPUs, GPUs, and FPGAs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXeoxARb7iT5"
      },
      "source": [
        "The following piece of code is taken from https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html, you can see more on how to infer using a model in ONNX format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0vuklYg8cNB",
        "outputId": "106ca371-d690-415e-aa99-55e4822fe42f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: onnx in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (1.15.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from onnx) (1.22.3)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from onnx) (4.24.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "C9Ii6PEk9wcS"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 3x(Conv2d -> ReLU) -> MaxPool -> Dropout -> Flatten -> 2x(Linear ->  ReLU) -> Linear\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(in_features=11*11*64, out_features=128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
        "        self.fc3 = nn.Linear(in_features=64, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## 3x(Conv2d -> ReLU) -> MaxPool -> Dropout -> Flatten -> 2x(Linear ->  ReLU) -> Linear\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deObUwwf6Ab-",
        "outputId": "c50ae9eb-4e55-43e0-886c-2118f37661f5"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "import torch.onnx\n",
        "\n",
        "model = Net()\n",
        "input = torch.randn(1, 1, 28, 28)\n",
        "\n",
        "torch.onnx.export(model,                     # model being run\n",
        "                  input,                     # model input (or a tuple for multiple inputs)\n",
        "                  \"example.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                                'output' : {0 : 'batch_size'}})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIz_SgFzAZ1E"
      },
      "source": [
        "Finally, we will download the model and upload it to https://netron.app/ to visualize and debug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Exercise 1: Implement ResNet-18**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "resnet_18 = models.resnet18()\n",
        "input = torch.randn(1, 3, 224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary(resnet_18, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.onnx.export(resnet_18,\n",
        "                  input, \n",
        "                  \"resnet_18.onnx\",\n",
        "                  export_params=True,\n",
        "                  opset_version=10,\n",
        "                  do_constant_folding=True,\n",
        "                  input_names = ['input'],\n",
        "                  output_names = ['output'],\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},\n",
        "                                'output' : {0 : 'batch_size'}})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Exercise 2: Use thop library to verify the number of parameters & FLOPs of VGG16 and ResNet 101**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.models import vgg16, resnet101\n",
        "from thop import profile\n",
        "from thop import clever_format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Params and FLOPs of VGG 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n"
          ]
        }
      ],
      "source": [
        "vgg16_ = vgg16()\n",
        "input = torch.randn(1, 3, 224, 224)\n",
        "flops, params = profile(vgg16_, inputs=(input, ))\n",
        "flops, params = clever_format([flops, params], \"%.3f\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('15.470G', '138.358M')"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flops, params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Params and FLOPs of ResNet 101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
          ]
        }
      ],
      "source": [
        "vgg16_ = resnet101()\n",
        "input = torch.randn(1, 3, 224, 224)\n",
        "flops, params = profile(vgg16_, inputs=(input, ))\n",
        "flops, params = clever_format([flops, params], \"%.3f\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('7.866G', '44.549M')"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flops, params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
